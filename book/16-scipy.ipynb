{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Methods using Python (scipy)\n",
    "\n",
    "## Overview\n",
    "\n",
    "The core Python language (including the standard libraries) provide enough functionality to carry out computational research tasks. However, there are dedicated (third-party) Python libraries that provide extended functionality which\n",
    "\n",
    "-   provide numerical tools for frequently occurring tasks\n",
    "\n",
    "-   which are convenient to use\n",
    "\n",
    "-   and are more efficient in terms of CPU time and memory requirements than using the code Python functionality alone.\n",
    "\n",
    "We list three such modules in particular:\n",
    "\n",
    "-   The `numpy` module provides a data type specialised for “number crunching” of vectors and matrices (this is the `array` type provided by “`numpy`” as introduced in [14-numpy.ipynb](14-numpy.ipynb)), and linear algebra tools.\n",
    "\n",
    "-   The `matplotlib` package (also knows as `pylab`) provides plotting and visualisation capabilities (see [15-visualising-data.ipynb](15-visualising-data.ipynb)) and the\n",
    "\n",
    "-   `scipy` package (SCIentific PYthon) which provides a multitude of numerical algorithms and which is introduced in this chapter.\n",
    "\n",
    "Many of the numerical algorithms available through `scipy` and `numpy` are provided by established compiled libraries which are often written in Fortran or C. They will thus execute much faster than pure Python code (which is interpreted). As a rule of thumb, we expect compiled code to be two orders of magnitude faster than pure Python code.\n",
    "\n",
    "You can use the help function for each numerical method to find out more about the source of the implementation.\n",
    "\n",
    "## SciPy\n",
    "\n",
    "`Scipy` provides many scientific computing functions and is generally complementary to the the functionality of `numpy`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy` package provides information about its own structure when we use the help command:\n",
    "\n",
    "```python\n",
    "help(scipy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is very long, so we're showing just a part of it here:\n",
    "\n",
    "     cluster                      --- Vector Quantization / Kmeans\n",
    "     fft                          --- Discrete Fourier transforms\n",
    "     fftpack                      --- Legacy discrete Fourier transforms\n",
    "     integrate                    --- Integration routines\n",
    "     interpolate                  --- Interpolation Tools\n",
    "     io                           --- Data input and output\n",
    "     linalg                       --- Linear algebra routines\n",
    "     linalg.blas                  --- Wrappers to BLAS library\n",
    "     linalg.lapack                --- Wrappers to LAPACK library\n",
    "     misc                         --- Various utilities that don't have\n",
    "                                      another home.\n",
    "     ndimage                      --- n-dimensional image package\n",
    "     odr                          --- Orthogonal Distance Regression\n",
    "     optimize                     --- Optimization Tools\n",
    "     signal                       --- Signal Processing Tools\n",
    "     signal.windows               --- Window functions\n",
    "     sparse                       --- Sparse Matrices\n",
    "     sparse.linalg                --- Sparse Linear Algebra\n",
    "     sparse.linalg.dsolve         --- Linear Solvers\n",
    "     sparse.linalg.dsolve.umfpack --- :Interface to the UMFPACK library:\n",
    "                                      Conjugate Gradient Method (LOBPCG)\n",
    "     sparse.linalg.eigen          --- Sparse Eigenvalue Solvers\n",
    "     sparse.linalg.eigen.lobpcg   --- Locally Optimal Block Preconditioned\n",
    "                                      Conjugate Gradient Method (LOBPCG)\n",
    "     spatial                      --- Spatial data structures and algorithms\n",
    "     special                      --- Special functions\n",
    "     stats                        --- Statistical Functions\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are looking for an algorithm to integrate a function, we might explore the `integrate` package:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import scipy.integrate\n",
    "```\n",
    "```text\n",
    "scipy.integrate?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produces:\n",
    "\n",
    "```text\n",
    "=============================================\n",
    "Integration and ODEs (:mod:`scipy.integrate`)\n",
    "=============================================\n",
    "\n",
    ".. currentmodule:: scipy.integrate\n",
    "\n",
    "Integrating functions, given function object\n",
    "============================================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   quad          -- General purpose integration\n",
    "   quad_vec      -- General purpose integration of vector-valued functions\n",
    "   dblquad       -- General purpose double integration\n",
    "   tplquad       -- General purpose triple integration\n",
    "   nquad         -- General purpose n-dimensional integration\n",
    "   fixed_quad    -- Integrate func(x) using Gaussian quadrature of order n\n",
    "   quadrature    -- Integrate with given tolerance using Gaussian quadrature\n",
    "   romberg       -- Integrate func using Romberg integration\n",
    "   quad_explain  -- Print information for use of quad\n",
    "   newton_cotes  -- Weights and error coefficient for Newton-Cotes integration\n",
    "   IntegrationWarning -- Warning on issues during integration\n",
    "\n",
    "Integrating functions, given fixed samples\n",
    "==========================================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   trapz         -- Use trapezoidal rule to compute integral.\n",
    "   cumtrapz      -- Use trapezoidal rule to cumulatively compute integral.\n",
    "   simps         -- Use Simpson's rule to compute integral from samples.\n",
    "   romb          -- Use Romberg Integration to compute integral from\n",
    "                 -- (2**k + 1) evenly-spaced samples.\n",
    "\n",
    ".. seealso::\n",
    "\n",
    "   :mod:`scipy.special` for orthogonal polynomials (special) for Gaussian\n",
    "   quadrature roots and weights for other weighting factors and regions.\n",
    "\n",
    "Solving initial value problems for ODE systems\n",
    "==============================================\n",
    "\n",
    "The solvers are implemented as individual classes which can be used directly\n",
    "(low-level usage) or through a convenience function.\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   solve_ivp     -- Convenient function for ODE integration.\n",
    "   RK23          -- Explicit Runge-Kutta solver of order 3(2).\n",
    "   RK45          -- Explicit Runge-Kutta solver of order 5(4).\n",
    "   DOP853        -- Explicit Runge-Kutta solver of order 8.\n",
    "   Radau         -- Implicit Runge-Kutta solver of order 5.\n",
    "   BDF           -- Implicit multi-step variable order (1 to 5) solver.\n",
    "   LSODA         -- LSODA solver from ODEPACK Fortran package.\n",
    "   OdeSolver     -- Base class for ODE solvers.\n",
    "   DenseOutput   -- Local interpolant for computing a dense output.\n",
    "   OdeSolution   -- Class which represents a continuous ODE solution.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections show examples which demonstrate how to employ the algorithms provided by `scipy`.\n",
    "\n",
    "## Numerical integration\n",
    "\n",
    "Scientific Python provides a number of integration routines. A general purpose tool to solve integrals *I* of the kind\n",
    "\n",
    "$$I=\\int_a^b f(x) \\mathrm{d} x$$\n",
    "\n",
    "is provided by the `quad()` function of the `scipy.integrate` module.\n",
    "\n",
    "It takes as input arguments the function *f*(*x*) to be integrated (the “integrand”), and the lower and upper limits *a* and *b*. It returns two values (in a tuple): the first one is the computed results and the second one is an estimation of the numerical error of that result.\n",
    "\n",
    "Here is an example: which produces this output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "from math import cos, exp, pi\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# function we want to integrate\n",
    "def f(x):\n",
    "    return exp(cos(-2 * x * pi)) + 3.2\n",
    "\n",
    "# call quad to integrate f from -2 to 2\n",
    "res, err = quad(f, -2, 2)\n",
    "\n",
    "print(\"The numerical result is {:f} (+-{:g})\"\n",
    "    .format(res, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `quad()` takes optional parameters `epsabs` and `epsrel` to increase or decrease the accuracy of its computation. (Use `help(quad)` to learn more.) The default values are `epsabs=1.5e-8` and `epsrel=1.5e-8`. For the next exercise, the default values are sufficient.\n",
    "\n",
    "### Exercise: integrate a function\n",
    "\n",
    "1.  Using scipy’s `quad` function, write a program that solves the following integral numerically: $I = \\int\n",
    "_0^1\\cos(2\\pi x) dx$.\n",
    "\n",
    "2.  Find the analytical integral and compare it with the numerical solution.\n",
    "\n",
    "3.  Why is it important to have an estimate of the accuracy (or the error) of the numerical integral?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: plot before you integrate\n",
    "\n",
    "It is good practice to plot the integrand function to check whether it is “well behaved” before you attempt to integrate. Singularities (i.e. $x$ values where the $f(x)$ tends towards minus or plus infinity) or other irregular behaviour (such as $f(x)=\\sin(\\frac{1}{x}$) close to $x = 0$ are difficult to handle numerically.\n",
    "\n",
    "1.  Write a function with name `plotquad` which takes the same arguments as the quad command (*i.e.* $f$, $a$ and $b$) and which \n",
    "- (i) creates a plot of the integrand $f(x)$ and \n",
    "- (ii) computes the integral numerically using the `quad` function. The return values should be as for the `quad` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# settings for jupyter book: svg for html version, high-resolution png for pdf\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg', 'png')\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('svg', 'png')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Ordinary Differential Equations (ODEs)\n",
    "\n",
    "To solve an ordinary differential equation of the type\n",
    "$$\\frac{\\mathrm{d}y}{\\mathrm{d}t}(t) = f(t, y)$$\n",
    "\n",
    "with a given $y(t_0)=y_0$, we can use `scipy`’s `solve_ivp` function. Here is a (self explaining) example program (`usesolve_ivp.py`) to find \n",
    "\n",
    "$$y(t) \\quad \\mathrm{for}\\quad t\\in[0,2]$$\n",
    " given this differential equation:\n",
    "$$\\frac{\\mathrm{d}y}{\\mathrm{d}t}(t) = -2yt \\quad \\mathrm{with} \\quad y(0)=1.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "import numpy as np\n",
    "\n",
    "def f(t, y):\n",
    "    \"\"\"this is the rhs of the ODE to integrate, i.e. dy/dt=f(y,t)\"\"\"\n",
    "    return -2 * y * t\n",
    "\n",
    "y0 = [1]           # initial value y0=y(t0)\n",
    "t0 = 0             # integration limits for t: start at t0=0\n",
    "tf = 2             # and finish at tf=2\n",
    "\n",
    "sol = solve_ivp(fun=f, t_span=[t0, tf], y0=y0)  # computation of SOLution \n",
    "\n",
    "import pylab          # plotting of results\n",
    "pylab.plot(sol.t, sol.y[0], 'o-')\n",
    "pylab.xlabel('t'); pylab.ylabel('y(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not given the `solve_ivp` command any guidance for which values of $t$ we would like to know the solution $y(t)$: we have only specified that $t_0 = 0$ and that we would like to know the solution between $t_0=0$ and $t_y=2$. The solver itself has determined the number of required function evaluations, and returns the corresponding values in `sol.t` and `sol.y[0]`.\n",
    "\n",
    "We can obtain more data points in a number of ways:\n",
    "\n",
    "1. Increase the default error tolerance. The relative tolerance (`rtol`) and absolute tolerance (`atol`) default to `1e-3` each. If we increase them, we typically enforce the use of a larger number of intermediate points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve_ivp(fun=f, t_span=[t0, tf], y0=y0, atol=1e-8, rtol=1e-8)\n",
    "\n",
    "pylab.plot(sol.t, sol.y[0], '.')\n",
    "pylab.xlabel('t'); pylab.ylabel('y(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We can also prescribe the precise locations for which we like to know the solutions $y(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = [1]           # initial value\n",
    "t0 = 0             # integration limits for t\n",
    "tf = 2              \n",
    "ts = np.linspace(t0, tf, 100)  # 100 points between t0 and tf\n",
    "\n",
    "sol = solve_ivp(fun=f, t_span=[t0, tf], y0=y0, t_eval=ts) \n",
    "\n",
    "pylab.plot(sol.t, sol.y[0], '.')\n",
    "pylab.xlabel('t'); pylab.ylabel('y(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `t_eval` - and thus request values of the solution at particular points - `solve_ivp` will not generally change the way it computes the solution, but rather use interpolation to map the way it has internally computed the solution to the values of t for which we would like to know the solution. There is thus no (significant) computational penalty if we use `t_eval` to get smoother looking plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `solve_ivp` command returns a `OdeResult` object, which we have called `sol` in the example above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen that the solution can be found in `sol.y` and `sol.t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sol.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sol.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `solve_ivp` is designed to integrate *systems* of ordinary differential equations, `sol.y` is a matrix, where each row contains the values for one degree of freedom. In our simple example above, we only have one degree of freedom ($y$). This is the reason, why we had to use `sol.y[0]` to access the solution values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other interesting attributes of the `OdeResult` object are the number of function evaluations that were necessary (where the function is the function `f` which computes the right hand side of the ODE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.nfev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a human-readable string, providing - for this example - a re-assuring message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine readable status is available in the `sol.status` attribute (0 is good):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `solve_ivp` command takes a number of optional parameters - we have already seen `atol` and `rtol` to change the default error tolerance of the integration. We can use the `help` command to explore these. The help string also explains the attributes of the solution object `OdeResult` in more detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "help(scipy.integrate.solve_ivp)\n",
    "```\n",
    "\n",
    "will show:\n",
    "\n",
    "```\n",
    "Help on function solve_ivp in module scipy.integrate._ivp.ivp:\n",
    "\n",
    "solve_ivp(fun, t_span, y0, method='RK45', t_eval=None, dense_output=False, events=None, vectorized=False, args=None, **options)\n",
    "    Solve an initial value problem for a system of ODEs.\n",
    "    \n",
    "    This function numerically integrates a system of ordinary differential\n",
    "    equations given an initial value::\n",
    "    \n",
    "        dy / dt = f(t, y)\n",
    "        y(t0) = y0\n",
    "    \n",
    "    Here t is a 1-D independent variable (time), y(t) is an\n",
    "    N-D vector-valued function (state), and an N-D\n",
    "    vector-valued function f(t, y) determines the differential equations.\n",
    "    The goal is to find y(t) approximately satisfying the differential\n",
    "    equations, given an initial value y(t0)=y0.\n",
    "    \n",
    "    Some of the solvers support integration in the complex domain, but note\n",
    "    that for stiff ODE solvers, the right-hand side must be\n",
    "    complex-differentiable (satisfy Cauchy-Riemann equations [11]_).\n",
    "    To solve a problem in the complex domain, pass y0 with a complex data type.\n",
    "    Another option always available is to rewrite your problem for real and\n",
    "    imaginary parts separately.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fun : callable\n",
    "        Right-hand side of the system. The calling signature is ``fun(t, y)``.\n",
    "        Here `t` is a scalar, and there are two options for the ndarray `y`:\n",
    "        It can either have shape (n,); then `fun` must return array_like with\n",
    "        shape (n,). Alternatively, it can have shape (n, k); then `fun`\n",
    "        must return an array_like with shape (n, k), i.e., each column\n",
    "        corresponds to a single column in `y`. The choice between the two\n",
    "        options is determined by `vectorized` argument (see below). The\n",
    "        vectorized implementation allows a faster approximation of the Jacobian\n",
    "        by finite differences (required for stiff solvers).\n",
    "    t_span : 2-tuple of floats\n",
    "        Interval of integration (t0, tf). The solver starts with t=t0 and\n",
    "        integrates until it reaches t=tf.\n",
    "    y0 : array_like, shape (n,)\n",
    "        Initial state. For problems in the complex domain, pass `y0` with a\n",
    "        complex data type (even if the initial value is purely real).\n",
    "    method : string or `OdeSolver`, optional\n",
    "        Integration method to use:\n",
    "    \n",
    "            * 'RK45' (default): Explicit Runge-Kutta method of order 5(4) [1]_.\n",
    "              The error is controlled assuming accuracy of the fourth-order\n",
    "              method, but steps are taken using the fifth-order accurate\n",
    "              formula (local extrapolation is done). A quartic interpolation\n",
    "              polynomial is used for the dense output [2]_. Can be applied in\n",
    "              the complex domain.\n",
    "            * 'RK23': Explicit Runge-Kutta method of order 3(2) [3]_. The error\n",
    "              is controlled assuming accuracy of the second-order method, but\n",
    "              steps are taken using the third-order accurate formula (local\n",
    "              extrapolation is done). A cubic Hermite polynomial is used for the\n",
    "              dense output. Can be applied in the complex domain.\n",
    "            * 'DOP853': Explicit Runge-Kutta method of order 8 [13]_.\n",
    "              Python implementation of the \"DOP853\" algorithm originally\n",
    "              written in Fortran [14]_. A 7-th order interpolation polynomial\n",
    "              accurate to 7-th order is used for the dense output.\n",
    "              Can be applied in the complex domain.\n",
    "            * 'Radau': Implicit Runge-Kutta method of the Radau IIA family of\n",
    "              order 5 [4]_. The error is controlled with a third-order accurate\n",
    "              embedded formula. A cubic polynomial which satisfies the\n",
    "              collocation conditions is used for the dense output.\n",
    "            * 'BDF': Implicit multi-step variable-order (1 to 5) method based\n",
    "              on a backward differentiation formula for the derivative\n",
    "              approximation [5]_. The implementation follows the one described\n",
    "              in [6]_. A quasi-constant step scheme is used and accuracy is\n",
    "              enhanced using the NDF modification. Can be applied in the\n",
    "              complex domain.\n",
    "            * 'LSODA': Adams/BDF method with automatic stiffness detection and\n",
    "              switching [7]_, [8]_. This is a wrapper of the Fortran solver\n",
    "              from ODEPACK.\n",
    "    \n",
    "        Explicit Runge-Kutta methods ('RK23', 'RK45', 'DOP853') should be used\n",
    "        for non-stiff problems and implicit methods ('Radau', 'BDF') for\n",
    "        stiff problems [9]_. Among Runge-Kutta methods, 'DOP853' is recommended\n",
    "        for solving with high precision (low values of `rtol` and `atol`).\n",
    "    \n",
    "        If not sure, first try to run 'RK45'. If it makes unusually many\n",
    "        iterations, diverges, or fails, your problem is likely to be stiff and\n",
    "        you should use 'Radau' or 'BDF'. 'LSODA' can also be a good universal\n",
    "        choice, but it might be somewhat less convenient to work with as it\n",
    "        wraps old Fortran code.\n",
    "    \n",
    "        You can also pass an arbitrary class derived from `OdeSolver` which\n",
    "        implements the solver.\n",
    "    t_eval : array_like or None, optional\n",
    "        Times at which to store the computed solution, must be sorted and lie\n",
    "        within `t_span`. If None (default), use points selected by the solver.\n",
    "    dense_output : bool, optional\n",
    "        Whether to compute a continuous solution. Default is False.\n",
    "    events : callable, or list of callables, optional\n",
    "        Events to track. If None (default), no events will be tracked.\n",
    "        Each event occurs at the zeros of a continuous function of time and\n",
    "        state. Each function must have the signature ``event(t, y)`` and return\n",
    "        a float. The solver will find an accurate value of `t` at which\n",
    "        ``event(t, y(t)) = 0`` using a root-finding algorithm. By default, all\n",
    "        zeros will be found. The solver looks for a sign change over each step,\n",
    "        so if multiple zero crossings occur within one step, events may be\n",
    "        missed. Additionally each `event` function might have the following\n",
    "        attributes:\n",
    "    \n",
    "            terminal: bool, optional\n",
    "                Whether to terminate integration if this event occurs.\n",
    "                Implicitly False if not assigned.\n",
    "            direction: float, optional\n",
    "                Direction of a zero crossing. If `direction` is positive,\n",
    "                `event` will only trigger when going from negative to positive,\n",
    "                and vice versa if `direction` is negative. If 0, then either\n",
    "                direction will trigger event. Implicitly 0 if not assigned.\n",
    "    \n",
    "        You can assign attributes like ``event.terminal = True`` to any\n",
    "        function in Python.\n",
    "    vectorized : bool, optional\n",
    "        Whether `fun` is implemented in a vectorized fashion. Default is False.\n",
    "    args : tuple, optional\n",
    "        Additional arguments to pass to the user-defined functions.  If given,\n",
    "        the additional arguments are passed to all user-defined functions.\n",
    "        So if, for example, `fun` has the signature ``fun(t, y, a, b, c)``,\n",
    "        then `jac` (if given) and any event functions must have the same\n",
    "        signature, and `args` must be a tuple of length 3.\n",
    "    options\n",
    "        Options passed to a chosen solver. All options available for already\n",
    "        implemented solvers are listed below.\n",
    "    first_step : float or None, optional\n",
    "        Initial step size. Default is `None` which means that the algorithm\n",
    "        should choose.\n",
    "    max_step : float, optional\n",
    "        Maximum allowed step size. Default is np.inf, i.e., the step size is not\n",
    "        bounded and determined solely by the solver.\n",
    "    rtol, atol : float or array_like, optional\n",
    "        Relative and absolute tolerances. The solver keeps the local error\n",
    "        estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a\n",
    "        relative accuracy (number of correct digits). But if a component of `y`\n",
    "        is approximately below `atol`, the error only needs to fall within\n",
    "        the same `atol` threshold, and the number of correct digits is not\n",
    "        guaranteed. If components of y have different scales, it might be\n",
    "        beneficial to set different `atol` values for different components by\n",
    "        passing array_like with shape (n,) for `atol`. Default values are\n",
    "        1e-3 for `rtol` and 1e-6 for `atol`.\n",
    "    jac : array_like, sparse_matrix, callable or None, optional\n",
    "        Jacobian matrix of the right-hand side of the system with respect\n",
    "        to y, required by the 'Radau', 'BDF' and 'LSODA' method. The\n",
    "        Jacobian matrix has shape (n, n) and its element (i, j) is equal to\n",
    "        ``d f_i / d y_j``.  There are three ways to define the Jacobian:\n",
    "    \n",
    "            * If array_like or sparse_matrix, the Jacobian is assumed to\n",
    "              be constant. Not supported by 'LSODA'.\n",
    "            * If callable, the Jacobian is assumed to depend on both\n",
    "              t and y; it will be called as ``jac(t, y)``, as necessary.\n",
    "              For 'Radau' and 'BDF' methods, the return value might be a\n",
    "              sparse matrix.\n",
    "            * If None (default), the Jacobian will be approximated by\n",
    "              finite differences.\n",
    "    \n",
    "        It is generally recommended to provide the Jacobian rather than\n",
    "        relying on a finite-difference approximation.\n",
    "    jac_sparsity : array_like, sparse matrix or None, optional\n",
    "        Defines a sparsity structure of the Jacobian matrix for a finite-\n",
    "        difference approximation. Its shape must be (n, n). This argument\n",
    "        is ignored if `jac` is not `None`. If the Jacobian has only few\n",
    "        non-zero elements in *each* row, providing the sparsity structure\n",
    "        will greatly speed up the computations [10]_. A zero entry means that\n",
    "        a corresponding element in the Jacobian is always zero. If None\n",
    "        (default), the Jacobian is assumed to be dense.\n",
    "        Not supported by 'LSODA', see `lband` and `uband` instead.\n",
    "    lband, uband : int or None, optional\n",
    "        Parameters defining the bandwidth of the Jacobian for the 'LSODA'\n",
    "        method, i.e., ``jac[i, j] != 0 only for i - lband <= j <= i + uband``.\n",
    "        Default is None. Setting these requires your jac routine to return the\n",
    "        Jacobian in the packed format: the returned array must have ``n``\n",
    "        columns and ``uband + lband + 1`` rows in which Jacobian diagonals are\n",
    "        written. Specifically ``jac_packed[uband + i - j , j] = jac[i, j]``.\n",
    "        The same format is used in `scipy.linalg.solve_banded` (check for an\n",
    "        illustration).  These parameters can be also used with ``jac=None`` to\n",
    "        reduce the number of Jacobian elements estimated by finite differences.\n",
    "    min_step : float, optional\n",
    "        The minimum allowed step size for 'LSODA' method.\n",
    "        By default `min_step` is zero.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch object with the following fields defined:\n",
    "    t : ndarray, shape (n_points,)\n",
    "        Time points.\n",
    "    y : ndarray, shape (n, n_points)\n",
    "        Values of the solution at `t`.\n",
    "    sol : `OdeSolution` or None\n",
    "        Found solution as `OdeSolution` instance; None if `dense_output` was\n",
    "        set to False.\n",
    "    t_events : list of ndarray or None\n",
    "        Contains for each event type a list of arrays at which an event of\n",
    "        that type event was detected. None if `events` was None.\n",
    "    y_events : list of ndarray or None\n",
    "        For each value of `t_events`, the corresponding value of the solution.\n",
    "        None if `events` was None.\n",
    "    nfev : int\n",
    "        Number of evaluations of the right-hand side.\n",
    "    njev : int\n",
    "        Number of evaluations of the Jacobian.\n",
    "    nlu : int\n",
    "        Number of LU decompositions.\n",
    "    status : int\n",
    "        Reason for algorithm termination:\n",
    "    \n",
    "            * -1: Integration step failed.\n",
    "            *  0: The solver successfully reached the end of `tspan`.\n",
    "            *  1: A termination event occurred.\n",
    "    \n",
    "    message : string\n",
    "        Human-readable description of the termination reason.\n",
    "    success : bool\n",
    "        True if the solver reached the interval end or a termination event\n",
    "        occurred (``status >= 0``).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems of coupled ODEs\n",
    "\n",
    "We want to show one example of two first-order ODEs that are coupled. This helps to understand why the initial value `y0` in the above example had to be provided in a list (`[y0]`) and why the solution is `sol.y[0]` rather than just `sol.y`.\n",
    "\n",
    "We use the [Predator and prey example](http://www.scholarpedia.org/article/Predator-prey_model). Let\n",
    "- $p_1(t)$ be the number of rabbits and\n",
    "- $p_2(t)$ be the number of foxes at a given time $t$\n",
    "\n",
    "To compute the time dependence of $p_1$ and $p_2$:\n",
    "- Assume that rabbits proliferate at a rate $a$. Per unit time a number $a p_1$ of rabbits are born.\n",
    "- Assume that the number of rabbits is reduced by collisions with foxes: per unit time $c p_1 p_2$ rabbits are eaten.\n",
    "- Assume that birth rate of foxes depends only on food intake in form of rabbits.\n",
    "- Assume that foxes die a natural death at a rate $b$.\n",
    "  \n",
    "We put this together into the system of coupled ordinary differential equations:\n",
    "  \\begin{eqnarray}\n",
    "    \\label{eq:predprey}\n",
    "    \\frac{d p_1}{dt} &=& a p_1 - c p_1 p_2\\nonumber\\\\\n",
    "    \\frac{d p_1}{dt} &=& c p_1 p_2 - b p_2\\nonumber\n",
    "  \\end{eqnarray}\n",
    "\n",
    "We use the following parameters:\n",
    "\n",
    "- rabbit birth rate $a = 0.7$\n",
    "- rabbit-fox-collision rate $ c = 0.007$\n",
    "- fox death rate $b = 1$\n",
    "\n",
    "We want to solve this for $p_1(t_0)=70$ and $p_2(t_0)=50$ as initial values, starting at $t_0=0$ for 30 units of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "\n",
    "def rhs(t, y):\n",
    "    a = 0.7\n",
    "    c = 0.007\n",
    "    b = 1\n",
    "    p1 = y[0]\n",
    "    p2 = y[1]\n",
    "\n",
    "    dp1dt = a * p1 - c * p1 * p2\n",
    "    dp2dt = c * p1 * p2 - b * p2\n",
    "\n",
    "    return [dp1dt, dp2dt]\n",
    "\n",
    "\n",
    "p0 = [70, 50]      # initial condition\n",
    "t0 = 0\n",
    "tfinal = 30\n",
    "ts = np.linspace(t0, tfinal, 200)\n",
    "\n",
    "sol = solve_ivp(rhs, [t0, tfinal], p0, t_eval=ts)\n",
    "\n",
    "p1 = sol.y[0]                \n",
    "p2 = sol.y[1]                \n",
    "\n",
    "pylab.plot(sol.t, p1, label='rabbits')\n",
    "pylab.plot(sol.t, p2, '-og', label='foxes')\n",
    "pylab.legend()\n",
    "pylab.xlabel('t')\n",
    "pylab.savefig('predprey.pdf')\n",
    "pylab.savefig('predprey.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root finding\n",
    "\n",
    "If you try to find a $x$ such that\n",
    "$$f(x)=0$$\n",
    "then this is called *root finding*. Note that problems like $g(x)=h(x)$ fall in this category as you can rewrite them as $f(x)=g(x)−h(x)=0$.\n",
    "\n",
    "A number of root finding tools are available in `scipy`’s `optimize` module.\n",
    "\n",
    "### Root finding using the bisection method\n",
    "\n",
    "First we introduce the `bisect` algorithm which is (i) robust and (ii) slow but conceptually very simple.\n",
    "\n",
    "Suppose we need to compute the roots of *f*(*x*)=*x*<sup>3</sup> − 2*x*<sup>2</sup>. This function has a (double) root at *x* = 0 (this is trivial to see) and another root which is located between *x* = 1.5 (where *f*(1.5)= − 1.125) and *x* = 3 (where *f*(3)=9). It is pretty straightforward to see that this other root is located at *x* = 2. Here is a program that determines this root numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import bisect\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"returns f(x)=x^3-2x^2. Has roots at\n",
    "    x=0 (double root) and x=2\"\"\"\n",
    "    return x ** 3 - 2 * x ** 2\n",
    "\n",
    "# main program starts here\n",
    "x = bisect(f, 1.5, 3, xtol=1e-6)\n",
    "\n",
    "print(\"The root x is approximately x=%14.12g,\\n\"\n",
    "      \"the error is less than 1e-6.\" % (x))\n",
    "print(\"The exact error is %g.\" % (2 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bisect()` method takes three compulsory arguments: (i) the function *f*(*x*), (ii) a lower limit *a* (for which we have chosen 1.5 in our example) and (ii) an upper limit *b* (for which we have chosen 3). The optional parameter `xtol` determines the maximum error of the method.\n",
    "\n",
    "One of the requirements of the bisection method is that the interval \\[*a*, *b*\\] has to be chosen such that the function is either positive at *a* and negative at *b*, or that the function is negative at *a* and postive at *b*. In other words: *a* and *b* have to enclose a root.\n",
    "\n",
    "### Exercise: root finding using the bisect method\n",
    "\n",
    "1.  Write a program with name `sqrttwo.py` to determine an approximation of $\\sqrt{2}$ by finding a root *x* of the function $f(x)=2 − x^2$ using the bisection algorithm. Choose a tolerance for the approximation of the root of 10<sup>−8</sup>.\n",
    "\n",
    "2.  Document your choice of the initial bracket $[a, b]$ for the root: which values have you chosen for *a* and for *b* and why?\n",
    "\n",
    "3.  Study the results:\n",
    "\n",
    "    -   Which value for the root *x* does the bisection algorithm return?\n",
    "\n",
    "    -   Compute the value of $\\\\sqrt{2}$ using `math.sqrt(2)` and compare this with the approximation of the root. How big is the absolute error of *x*? How does this compare with `xtol`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root finding using the `fsolve` funcion\n",
    "\n",
    "A (often) better (in the sense of “more efficient”) algorithm than the bisection algorithm is implemented in the general purpose `fsolve()` function for root finding of (multidimensional) functions. This algorithm needs only one starting point close to the suspected location of the root (but is not garanteed to converge).\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "def f(x):\n",
    "    return x ** 3 - 2 * x ** 2\n",
    "\n",
    "x = fsolve(f, 3)           # one root is at x=2.0\n",
    "\n",
    "print(\"The root x is approximately x=%21.19g\" % x)\n",
    "print(\"The exact error is %g.\" % (2 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value[6] of `fsolve` is a numpy array of length *n* for a root finding problem with *n* variables. In the example above, we have *n* = 1.\n",
    "\n",
    "## Interpolation\n",
    "\n",
    "Given a set of *N* points $(x_i, y_i)$ with $i = 1, 2, …N$, we sometimes need a function $\\hat{f}(x)$ which returns $y_i = f(x_i)$ where $x == x_i$, and which in addition provides some interpolation of the data $(x_i, y_i)$ for all $x$.\n",
    "\n",
    "The function `y0 = scipy.interpolate.interp1d(x,y,kind=’nearest’)` does this interpolation based on splines of varying order. Note that the function `interp1d` returns *a function* `y0` which will then interpolate the x-y data for any given $x$ when called as $y0(x)$.\n",
    "\n",
    "The code below demonstrates this, and shows the different interpolation kinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import pylab\n",
    "\n",
    "def create_data(n):\n",
    "    \"\"\"Given an integer n, returns n data points\n",
    "    x and values y as a numpy.array.\"\"\"\n",
    "    xmax = 5.\n",
    "    x = np.linspace(0, xmax, n)\n",
    "    y = - x**2\n",
    "    #make x-data somewhat irregular\n",
    "    y += 1.5 * np.random.normal(size=len(x))\n",
    "    return x, y\n",
    "\n",
    "#main program\n",
    "n = 10\n",
    "x, y = create_data(n)\n",
    "\n",
    "#use finer and regular mesh for plot\n",
    "xfine = np.linspace(0.1, 4.9, n * 100)\n",
    "#interpolate with piecewise constant function (p=0)\n",
    "y0 = scipy.interpolate.interp1d(x, y, kind='nearest')\n",
    "#interpolate with piecewise linear func (p=1)\n",
    "y1 = scipy.interpolate.interp1d(x, y, kind='linear')\n",
    "#interpolate with piecewise constant func (p=2)\n",
    "y2 = scipy.interpolate.interp1d(x, y, kind='quadratic')\n",
    "\n",
    "pylab.plot(x, y, 'o', label='data point')\n",
    "pylab.plot(xfine, y0(xfine), label='nearest')\n",
    "pylab.plot(xfine, y1(xfine), label='linear')\n",
    "pylab.plot(xfine, y2(xfine), label='cubic')\n",
    "pylab.legend()\n",
    "pylab.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve fitting\n",
    "\n",
    "We have already seen in [the numpy chapter](14-numpy.ipynb) that we can fit polynomial functions through a data set using the `numpy.polyfit` function. Here, we introduce a more generic curve fitting algorithm.\n",
    "\n",
    "Scipy provides a somewhat generic function (based on the Levenburg-Marquardt algorithm )through `scipy.optimize.curve_fit` to fit a given (Python) function to a given data set. The assumption is that we have been given a set of data with points $x_1, x_2, …x_N$ and with corresponding function values $y_i$ and a dependence of $y_i$ on $x_i$ such that $y_i=f(x_i,\\vec{p})$. We want to determine the parameter vector $\\vec{p}=(p_1, p_2, \\ldots,\n",
    "p_k)$ so that $r$, the sum of the residuals, is as small as possible:\n",
    "\n",
    "$$r = \\sum\\limits_{i=1}^N \\left(y_i - f(x_i, \\vec{p})\\right)^2$$\n",
    "\n",
    "Curve fitting is of particular use if the data is noisy: for a given $x_i$ and $y_i=f(x_i,\\vec{p})$ we have a (unknown) error term $\\epsilon_i$ so that $y_i=f(x_i,\\vec{p})+\\epsilon_i$.\n",
    "\n",
    "We use the following example to clarify this:\n",
    "$$f(x,\\vec{p}) = a \\exp(-b x) + c, \\quad\\mathrm{i.e.}\\quad \\vec{p}=\\mathtt{a,b,c}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def f(x, a, b, c):\n",
    "    \"\"\"Fit function y=f(x,p) with parameters p=(a,b,c). \"\"\"\n",
    "    return a * np.exp(- b * x) + c\n",
    "\n",
    "#create fake data\n",
    "x = np.linspace(0, 4, 50)\n",
    "y = f(x, a=2.5, b=1.3, c=0.5)\n",
    "#add noise\n",
    "yi = y + 0.2 * np.random.normal(size=len(x))\n",
    "\n",
    "#call curve fit function\n",
    "popt, pcov = curve_fit(f, x, yi)\n",
    "a, b, c = popt\n",
    "print(\"Optimal parameters are a=%g, b=%g, and c=%g\" % (a, b, c))\n",
    "\n",
    "#plotting\n",
    "import pylab\n",
    "yfitted = f(x, *popt)   # equivalent to f(x, popt[0], popt[1], popt[2])\n",
    "pylab.plot(x, yi, 'o', label='data $y_i$')\n",
    "pylab.plot(x, yfitted, '-', label='fit $f(x_i)$')\n",
    "pylab.xlabel('x')\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the source code above we define the fitting function $y = f(x)$ through Python code. We can thus fit (nearly) arbitrary functions using the `curve_fit` method.\n",
    "\n",
    "The `curve_fit` function returns a tuple `popt, pcov`. The first entry `popt` contains a tuple of the OPTimal Parameters (in the sense that these minimise equation (\\[eq:1\\]). The second entry contains the covariance matrix for all parameters. The diagonals provide the variance of the parameter estimations.\n",
    "\n",
    "For the curve fitting process to work, the Levenburg-Marquardt algorithm needs to start the fitting process with initial guesses for the final parameters. If these are not specified (as in the example above), the value “1.0“ is used for the initial guess.\n",
    "\n",
    "If the algorithm fails to fit a function to data (even though the function describes the data reasonably), we need to give the algorithm better estimates for the initial parameters. For the example shown above, we could give the estimates to the `curve_fit` function by changing the line\n",
    "\n",
    "```python\n",
    "popt, pcov = curve_fit(f, x, yi)\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```python\n",
    "popt, pcov = curve_fit(f, x, yi, p0=(2, 1, 0.6))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if our initial guesses would be *a* = 2, *b* = 1 and *c* = 0.6. Once we take the algorithm “roughly in the right area” in parameter space, the fitting usually works well.\n",
    "\n",
    "## Fourier transforms\n",
    "\n",
    "In the next example, we create a signal as a superposition of a 50 Hz and 70 Hz sine wave (with a slight phase shift between them). We then Fourier transform the signal and plot the absolute value of the (complex) discrete Fourier transform coefficients against frequency, and expect to see peaks at 50Hz and 70Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.fft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pi = np.pi\n",
    "\n",
    "signal_length = 0.5     # [seconds]\n",
    "sample_rate = 500       # sampling rate [Hz]\n",
    "dt = 1. / sample_rate   # time between two samples [s]\n",
    "\n",
    "df = 1 / signal_length  # frequency between points in\n",
    "                        # in frequency domain [Hz] \n",
    "t = np.arange(0, signal_length, dt)  # the time vector\n",
    "n_t = len(t)            # length of time vector\n",
    "\n",
    "# create signal\n",
    "y = np.sin(2*pi*50*t) + np.sin(2*pi*70*t+pi/4)\n",
    "\n",
    "# compute Fourier transform\n",
    "f = scipy.fft.fft(y)\n",
    "\n",
    "# work out meaningful frequencies in Fourier transform\n",
    "freqs = df * np.arange(0, (n_t-1)/2., dtype='d')  # 'd'=double precision float\n",
    "n_freq = len(freqs)\n",
    "\n",
    "# plot input data y against time\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, y, label='input data')\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('signal')\n",
    "\n",
    "#plot frequency spectrum \n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(freqs, abs(f[0:n_freq]),\n",
    "         label='abs(fourier transform)')\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('abs(DFT(signal))');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower plot shows the discrete Fourier transform computed from the data shown in the upper plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "\n",
    "Often we need to find the maximum or minimum of a particular function *f*(*x*) where *f* is a scalar function but *x* could be a vector. Typical applications are the minimisation of entities such as cost, risk and error, or the maximisation of productivity, efficiency and profit. Optimisation routines typically provide a method to minimise a given function: if we need to maximise *f*(*x*) we create a new function *g*(*x*) that reverses the sign of *f*, i.e. *g*(*x*)= − *f*(*x*) and we minimise *g*(*x*).\n",
    "\n",
    "Below, we provide an example showing (i) the definition of the test function and (ii) the call of the `scipy.optimize.fmin` function which takes as argument a function *f* to minimise and an initial value *x*<sub>0</sub> from which to start the search for the minimum, and which returns the value of *x* for which *f*(*x*) is (locally) minimised. Typically, the search for the minimum is a local search, i.e. the algorithm follows the local gradient. We repeat the search for the minimum for two values (*x*<sub>0</sub> = 1.0 and *x*<sub>0</sub> = 2.0, respectively) to demonstrate that depending on the starting value we may find different minimar of the function *f*.\n",
    "\n",
    "The majority of the commands (after the two calls to `fmin`) in the file `fmin1.py` creates the plot of the function, the start points for the searches and the minima obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange, cos, exp\n",
    "from scipy.optimize import fmin\n",
    "import pylab\n",
    "\n",
    "def f(x):\n",
    "    return cos(x) - 3 * exp( -(x - 0.2) ** 2)\n",
    "\n",
    "# find minima of f(x),\n",
    "# starting from 1.0 and 2.0 respectively\n",
    "minimum1 = fmin(f, 1.0)\n",
    "print(\"Start search at x=1., minimum is\", minimum1)\n",
    "minimum2 = fmin(f, 2.0)\n",
    "print(\"Start search at x=2., minimum is\", minimum2)\n",
    "\n",
    "# plot function\n",
    "x = arange(-10, 10, 0.1)\n",
    "y = f(x)\n",
    "pylab.plot(x, y, label='$\\cos(x)-3e^{-(x-0.2)^2}$')\n",
    "pylab.xlabel('x')\n",
    "pylab.grid()\n",
    "pylab.axis([-5, 5, -2.2, 0.5])\n",
    "\n",
    "# add minimum1 to plot\n",
    "pylab.plot(minimum1, f(minimum1), 'vr',\n",
    "           label='minimum 1')\n",
    "# add start1 to plot\n",
    "pylab.plot(1.0, f(1.0), 'or', label='start 1')\n",
    "\n",
    "# add minimum2 to plot\n",
    "pylab.plot(minimum2,f(minimum2),'vg',\\\n",
    "           label='minimum 2')\n",
    "# add start2 to plot\n",
    "pylab.plot(2.0,f(2.0),'og',label='start 2')\n",
    "\n",
    "pylab.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `fmin` function will produce some diagnostic output, which you can also see above.\n",
    "\n",
    "**Return value of `fmin`**\n",
    "\n",
    "Note that the return value from the `fmin` function is a numpy `array` which – for the example above – contains only one number as we have only one parameter (here *x*) to vary. In general, `fmin` can be used to find the minimum in a higher-dimensional parameter space if there are several parameters. In that case, the numpy array would contain those parameters that minimise the objective function. The objective function $f(x)$ has to return a scalar even if there are more parameters, i.e. even if $x$ is a vector as in $f(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other numerical methods\n",
    "\n",
    "Scientific Python and Numpy provide access to a large number of other numerical algorithms including function interpolation, Fourier transforms, optimisation, special functions (such as Bessel functions), signal processing and filters, random number generation, and more. Start to explore `scipy`’s and `numpy`’s capabilities using the `help` function and the documentation provided on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.io: Scipy-input output\n",
    "\n",
    "Scipy provides routines to read and write Matlab `mat` files. Here is an example where we create a Matlab compatible file storing a (1x11) matrix, and then read this data into a numpy array from Python using the scipy Input-Output library:\n",
    "\n",
    "First we create a mat file in Octave (Octave is \\[mostly\\] compatible with Matlab):\n",
    "\n",
    "```octave\n",
    "octave:1> a=-1:0.5:4\n",
    "a =\n",
    "Columns 1 through 6:\n",
    "   -1.0000   -0.5000    0.0000    0.5000    1.0000    1.5000    \n",
    "Columns 7 through 11:\n",
    "   2.0000    2.5000   3.0000    3.5000    4.0000\n",
    "octave:2> save -6 octave_a.mat a       %save as version 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load this array within python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "mat_contents = loadmat('static/data/octave_a.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `loadmat` returns a dictionary: the key for each item in the dictionary is a string which is the name of that array when it was saved in Matlab. The key is the actual array.\n",
    "\n",
    "A Matlab matrix file can hold several arrays. Each of those is presented by one key-value pair in the dictionary.\n",
    "\n",
    "Let’s save two arrays from Python to demonstrate that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# create two numpy arrays\n",
    "a = np.linspace(0, 50, 11)\n",
    "b = np.ones((4, 4))\n",
    "\n",
    "# save as mat-file\n",
    "# create dictionary for savemat\n",
    "tmp_d = {'a': a,\n",
    "         'b': b}\n",
    "scipy.io.savemat('data.mat', tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program creates the file `data.mat`, which we can subsequently read using Matlab or here Octave:\n",
    "\n",
    "    HAL47:code fangohr$ octave\n",
    "    GNU Octave, version 3.2.4\n",
    "    Copyright (C) 2009 John W. Eaton and others.\n",
    "    <snip>\n",
    "\n",
    "    octave:1> whos\n",
    "    Variables in the current scope:\n",
    "\n",
    "      Attr Name        Size                     Bytes  Class\n",
    "      ==== ====        ====                     =====  ===== \n",
    "           ans         1x11                        92  cell\n",
    "\n",
    "    Total is 11 elements using 92 bytes\n",
    "\n",
    "    octave:2> load data.mat\n",
    "    octave:3> whos\n",
    "    Variables in the current scope:\n",
    "\n",
    "      Attr Name        Size                     Bytes  Class\n",
    "      ==== ====        ====                     =====  ===== \n",
    "           a          11x1                         88  double\n",
    "           ans         1x11                        92  cell\n",
    "           b           4x4                        128  double\n",
    "\n",
    "    Total is 38 elements using 308 bytes\n",
    "\n",
    "    octave:4> a\n",
    "    a =\n",
    "\n",
    "        0\n",
    "        5\n",
    "       10\n",
    "       15\n",
    "       20\n",
    "       25\n",
    "       30\n",
    "       35\n",
    "       40\n",
    "       45\n",
    "       50\n",
    "\n",
    "    octave:5> b\n",
    "    b =\n",
    "\n",
    "       1   1   1   1\n",
    "       1   1   1   1\n",
    "       1   1   1   1\n",
    "       1   1   1   1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are other functions to read from and write to in formats as used by IDL, Netcdf and other formats in `scipy.io`.\n",
    "\n",
    "More → see [Scipy tutorial](https://docs.scipy.org/doc/scipy/reference/io.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}